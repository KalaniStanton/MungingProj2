# Token Analysis {#token-analysis}

This chapter contains the code for wrangling the cleaned and tokenized data into data-frames containing word frequencies and visualizing the data using the raw counts derived from this process.

```{r TA_setup}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = TRUE)
# set to TRUE to run this on only one reference file
debugging <- FALSE
# this will expect the file or files to be in a subdirectory with the following name
refsource <- "MungingProj2"
dataDir <- "Proj2Data"
workingDir <- refsource

# prefixes for all File reads and writes
# titles for tables
titletext <- "RedditCrypto"
srs = c("CryptoCurrency","CryptoMarkets")

`%notin%` <- Negate(`%in%`)
```

## Import

```{r import_submissions, include = TRUE, echo = FALSE}
TknsS<- read.csv(paste0(dataDir, "/SubmTkns.csv")) 
TknsC<- read.csv(paste0(dataDir, "/CommTkns.csv"))
```

## Token Counts

```{r count}
allCount <-TknsC %>% #group words by affiliation label
    count(word, sort = TRUE) %>%
    ungroup()
```


### Most Frequent Tokens

The following code show the top 25 most frequently occuring words within each subreddit.

```{r top_25}
sr_all_n25 <- allCount %>% 
  top_n(25) %>%
  ungroup()

kable(sr_all_n25)
```

## Wordclouds

Wordcloud is constructed using the top 100 words.

```{r wc_allCount}
#sr_allCount <- allCount %>% filter(!subreddit == "r/all [control]")
sr_allWC <- allCount %>%
  top_n(100) %>%
  mutate(prop = n / max(n))
```


```{r wordcloud1, warnings = FALSE, messages = FALSE}
set.seed(29)
ggplot(sr_allWC, aes(label = word, size = prop, color = prop)) +
    geom_text_wordcloud_area(shape = 'circle', rm_outside = TRUE) +
    scale_size_area(max_size = 30) +
    theme_minimal()

ggsave("CC_wordcloud.pdf", device = "pdf", path = "CCViz", height = 10, width = 16)
```


### Wordclouds over time

```{r split_dates}
TknsByDate <- TknsC %>%
  separate(created, c("created", "time"), " ") %>%
  mutate(created = ymd(created)) %>%
  mutate_at(vars(created), funs(year, month, day))
```

```{r month_count}
TknsByMonth <-TknsByDate %>%
    filter(year > 2015) %>%
    mutate(Month = make_date(year, month))

monthCount <- TknsByMonth %>%
    group_by(subreddit, month, year) %>% #group words by affiliation label
    count(word, sort = TRUE) %>% #count and create column 'n'
    top_n(10, n) %>%
    ungroup()

monthCount <- monthCount %>%
    group_by(subreddit, month, year) %>%
    mutate(prop = n / max(n))
    
table(monthCount$subreddit)
```

```{r}
ggplot(monthCount, aes(
  label = word,
  size = prop,
  color = prop
)) +
  geom_text_wordcloud_area(rm_outside = TRUE) +
  scale_size_area(max_size = 5) +
  theme_minimal() +
  facet_grid(vars(month), vars(year))
```


## Currencies

```{r}
BTC <- c("Bitcoin", "bitcoin", "BTC", "btc", "Btc")
ETH <- c("Ethereum", "ethereum", "ETH", "eth", "Eth")
XRP <- c("Ripple", "ripple", "XRP", "xrp", "Xrp")
LTC <- c("Litecoin", "litecoin", "LTC", "ltc", "Ltc")

currencies <- c(BTC, ETH, XRP, LTC)

# For frequency analysis
CurTkns <- TknsByDate %>%
  filter(word %in% currencies)

# For sentiment analysis
CurComms <- CommData %>%
  filter(comm_id %in% CurTkns$comm_id)
```

### Assigning Identifiers

```{r}
CurTkns <- CurTkns %>%
  mutate(Coin = case_when(
    .$word %in% BTC ~ "BTC",
    .$word %in% ETH ~ "ETH",
    .$word %in% XRP ~ "XRP",
    .$word %in% LTC ~ "LTC"
  ))
```


```{r}
# Establish date column for grouping
curTknsByMonth <-CurTkns %>%
    mutate(Month = make_date(year, month))

curCounts <- curTknsByMonth %>%
    group_by(Coin) %>% #group words by affiliation label
    count(word, sort = TRUE) %>% #count and create column 'n'
    ungroup()

curCountsbyMonth <- curTknsByMonth %>%
    group_by(Coin, Month) %>% #group words by affiliation label
    count(word, sort = TRUE) %>% #count and create column 'n'
    ungroup()
```

```{r}
ggplot(curCounts) +
  geom_bar(aes(x = Coin, y = n, fill = Coin), stat = "identity")
```


```{r}
ggplot(curCountsbyMonth) +
  geom_bar(aes(x = Coin, y = n, fill = Coin), stat = "identity") +
  facet_wrap(~Month)
```

```{r}
write.csv(curTknsByMonth, paste0(dataDir, "/CoinTknsMonthly.csv"), row.names = FALSE)
```
